{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","mount_file_id":"150BCIoSw5Drv21Mtazh9uxlNvN01tmT-","authorship_tag":"ABX9TyOcuIjwp8EKmOu917SjIR82"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QV8UAd1td8Lq","executionInfo":{"status":"ok","timestamp":1764877301962,"user_tz":360,"elapsed":5,"user":{"displayName":"Joseph Havens","userId":"14169325784778486808"}},"outputId":"c43925a5-c3bf-49e0-cba5-e8a866d1ca5d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Libraries set up.\n"]}],"source":["# 1. Imports and Config\n","import pandas as pd\n","import numpy as np\n","import os\n","import sys\n","from tqdm import tqdm\n","\n","# --- Add Project Root to Python Path ---\n","try:\n","    PROJECT_ROOT = '/content/drive/MyDrive/NFL_Prediction_System'\n","    if PROJECT_ROOT not in sys.path:\n","        sys.path.append(str(PROJECT_ROOT))\n","except:\n","    pass\n","\n","from src.utils import config\n","\n","# Ensure the output directory exists\n","os.makedirs(config.FEATURES_DIR, exist_ok=True)\n","\n","# Settings\n","pd.set_option('display.max_columns', None)\n","ROLL_WINDOW_LIST = [3, 5, 8]  # The windows we want to test\n","\n","print(\"Libraries set up.\")"]},{"cell_type":"code","source":["# 2. Load All Datasets\n","print(\"Loading datasets...\")\n","\n","# A. Load Cleaned Game Data (The Stats)\n","try:\n","    game_data = pd.read_parquet(config.CLEANED_GAMES_PATH / 'game_data_2002_2023.parquet')\n","    print(f\"✅ Loaded Cleaned Game Data: {game_data.shape}\")\n","\n","    # Quick Sanity Check\n","    if 'home_off_epa_per_play' in game_data.columns:\n","        print(\"   -> Confirmed: EPA stats are present.\")\n","    else:\n","        raise ValueError(\"CRITICAL: Cleaned data is missing EPA stats!\")\n","\n","except FileNotFoundError:\n","    print(\"❌ Error: Cleaned game data not found. Please run 02_cleaning.ipynb.\")\n","\n","# B. Load Helper Files (for Rest, Rookies, Injuries)\n","try:\n","    schedule_df = pd.read_csv(config.RAW_GAMES_PATH / 'schedule_2002_2023.csv')\n","    roster_df = pd.read_parquet(config.RAW_PLAYERS_PATH / 'rosters_2002_2023.parquet')\n","    injury_df = pd.read_parquet(config.RAW_GAMES_PATH / 'injuries_2009_2023.parquet')\n","    seasonal_df = pd.read_parquet(config.RAW_TEAM_STATS_PATH / 'seasonal_team_data_2002_2023.parquet')\n","    print(f\"✅ Loaded Helper Data: Schedule, Rosters, Injuries, Seasonal Stats.\")\n","except Exception as e:\n","    print(f\"⚠️ Warning: Some helper files could not be loaded ({e}). Some features may be skipped.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AArR83__eHjw","executionInfo":{"status":"ok","timestamp":1764877302142,"user_tz":360,"elapsed":178,"user":{"displayName":"Joseph Havens","userId":"14169325784778486808"}},"outputId":"58d95a91-e142-42f4-bc6d-dbc82a0f6fb3"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading datasets...\n","✅ Loaded Cleaned Game Data: (5679, 37)\n","   -> Confirmed: EPA stats are present.\n","✅ Loaded Helper Data: Schedule, Rosters, Injuries, Seasonal Stats.\n"]}]},{"cell_type":"markdown","source":["# Part 1: Rolling Feature Functions (The \"Engine\")"],"metadata":{"id":"XUQH1_w3z_hv"}},{"cell_type":"code","source":["# 3. Create Rolling Features\n","print(\"Generating rolling features...\")\n","\n","# Step A: Convert to 'Long' format (Team-Game level)\n","# We take the clean game_data and stack home/away rows\n","stats_cols = [\n","    'off_epa_per_play', 'off_success_rate', 'off_pass_epa', 'off_run_epa', 'off_turnovers',\n","    'def_epa_per_play', 'def_success_rate', 'def_pass_epa', 'def_run_epa', 'def_turnovers_forced'\n","]\n","\n","# Home Perspective\n","home_df = game_data[['game_id', 'season', 'week', 'home_team']].rename(columns={'home_team': 'team'})\n","home_df['opponent'] = game_data['away_team']\n","home_df['is_home'] = 1\n","for col in stats_cols:\n","    home_df[col] = game_data[f'home_{col}']\n","\n","# Away Perspective\n","away_df = game_data[['game_id', 'season', 'week', 'away_team']].rename(columns={'away_team': 'team'})\n","away_df['opponent'] = game_data['home_team']\n","away_df['is_home'] = 0\n","for col in stats_cols:\n","    away_df[col] = game_data[f'away_{col}']\n","\n","# Combine\n","long_df = pd.concat([home_df, away_df]).sort_values(by=['team', 'season', 'week'])\n","\n","# Step B: Calculate Rolling Averages\n","# Group by Team and Season to prevent leakage across years\n","grouped = long_df.groupby(['team', 'season'])\n","all_rolling = [long_df]\n","\n","for window in ROLL_WINDOW_LIST:\n","    # Shift(1) is CRITICAL to prevent data leakage (using current game to predict current game)\n","    rolled = grouped[stats_cols].shift(1).rolling(window=window, min_periods=1).mean()\n","    rolled.columns = [f'{col}_roll{window}' for col in stats_cols]\n","    all_rolling.append(rolled)\n","\n","# Concatenate features back to long_df\n","long_with_features = pd.concat(all_rolling, axis=1)\n","\n","# Step C: Merge back to 'Wide' format (Game level)\n","# Split back into Home and Away to merge on game_id\n","home_feats = long_with_features[long_with_features['is_home'] == 1]\n","away_feats = long_with_features[long_with_features['is_home'] == 0]\n","\n","# Keep only the ID columns and the new rolling columns\n","keep_cols = ['game_id'] + [c for c in home_feats.columns if '_roll' in c]\n","\n","features_df = pd.merge(\n","    game_data, # Start with original game data\n","    home_feats[keep_cols].rename(columns={c: f'home_{c}' for c in keep_cols if c != 'game_id'}),\n","    on='game_id', how='left'\n",")\n","features_df = pd.merge(\n","    features_df,\n","    away_feats[keep_cols].rename(columns={c: f'away_{c}' for c in keep_cols if c != 'game_id'}),\n","    on='game_id', how='left'\n",")\n","\n","# Step D: Create Matchup Differentials (Home - Away)\n","# --- FIX: Explicit mapping for offense vs defense stats ---\n","stat_map = {\n","    'off_epa_per_play': 'def_epa_per_play',\n","    'off_success_rate': 'def_success_rate',\n","    'off_pass_epa': 'def_pass_epa',\n","    'off_run_epa': 'def_run_epa',\n","    'off_turnovers': 'def_turnovers_forced' # This was the one breaking it!\n","}\n","\n","for window in ROLL_WINDOW_LIST:\n","    for off_stat, def_stat in stat_map.items():\n","        home_off_col = f'home_{off_stat}_roll{window}'\n","        away_def_col = f'away_{def_stat}_roll{window}'\n","\n","        away_off_col = f'away_{off_stat}_roll{window}'\n","        home_def_col = f'home_{def_stat}_roll{window}'\n","\n","        # Matchup: Home Offense vs Away Defense\n","        features_df[f'home_{off_stat}_matchup_roll{window}'] = features_df[home_off_col] - features_df[away_def_col]\n","\n","        # Matchup: Away Offense vs Home Defense\n","        features_df[f'away_{off_stat}_matchup_roll{window}'] = features_df[away_off_col] - features_df[home_def_col]\n","\n","print(f\"Rolling features created. Current shape: {features_df.shape}\")"],"metadata":{"id":"K6jXIcyReI4Z","executionInfo":{"status":"ok","timestamp":1764877302156,"user_tz":360,"elapsed":14,"user":{"displayName":"Joseph Havens","userId":"14169325784778486808"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d2a59436-1f87-4fee-ca49-4d92e4722bcb"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["Generating rolling features...\n","Rolling features created. Current shape: (5679, 127)\n"]}]},{"cell_type":"code","source":["# 4. Add Context Features (Rest, Rookies, Injuries)\n","print(\"Adding context features...\")\n","\n","# --- A. Rest Days ---\n","# Requires 'schedule_df' (raw) because it has the dates\n","def calculate_rest(df):\n","    df['gameday'] = pd.to_datetime(df['gameday'])\n","    # Stack to get one row per team-game\n","    h = df[['season', 'week', 'gameday', 'home_team']].rename(columns={'home_team': 'team'})\n","    a = df[['season', 'week', 'gameday', 'away_team']].rename(columns={'away_team': 'team'})\n","    combined = pd.concat([h, a]).sort_values(['team', 'season', 'week'])\n","\n","    # Calculate days since last game\n","    combined['prev_game'] = combined.groupby(['team', 'season'])['gameday'].shift(1)\n","    combined['rest_days'] = (combined['gameday'] - combined['prev_game']).dt.days.fillna(7) # Default 7\n","    combined['rest_days'] = combined['rest_days'].clip(upper=15) # Cap at 15\n","    return combined[['season', 'week', 'team', 'rest_days']]\n","\n","try:\n","    rest_data = calculate_rest(schedule_df)\n","    # Merge Rest\n","    features_df = features_df.merge(rest_data, left_on=['season', 'week', 'home_team'], right_on=['season', 'week', 'team'], how='left').rename(columns={'rest_days': 'home_rest'}).drop(columns='team')\n","    features_df = features_df.merge(rest_data, left_on=['season', 'week', 'away_team'], right_on=['season', 'week', 'team'], how='left').rename(columns={'rest_days': 'away_rest'}).drop(columns='team')\n","    features_df['rest_advantage'] = features_df['home_rest'] - features_df['away_rest']\n","    print(\" -> Rest days added.\")\n","except Exception as e:\n","    print(f\" -> Skipped Rest Days: {e}\")\n","\n","# --- B. Rookie QBs ---\n","try:\n","    # Identify rookie QBs from roster data\n","    rookie_qbs = roster_df[(roster_df['position'] == 'QB') & (roster_df['season'] == roster_df['draft_year'])]\n","    # (Simplified logic: check if the 'qb_name' or 'qb_id' matches a rookie.\n","    #  For this version, we will check if the team *drafted* a QB that year and assume they might play.)\n","    #  A more precise way requires snap counts, but this is a good proxy.\n","    rookie_map = rookie_qbs.groupby(['season', 'team']).size().reset_index(name='has_rookie_qb')\n","\n","    features_df = features_df.merge(rookie_map, left_on=['season', 'home_team'], right_on=['season', 'team'], how='left').rename(columns={'has_rookie_qb': 'home_rookie_qb'}).drop(columns='team')\n","    features_df = features_df.merge(rookie_map, left_on=['season', 'away_team'], right_on=['season', 'team'], how='left').rename(columns={'has_rookie_qb': 'away_rookie_qb'}).drop(columns='team')\n","    features_df[['home_rookie_qb', 'away_rookie_qb']] = features_df[['home_rookie_qb', 'away_rookie_qb']].fillna(0)\n","    print(\" -> Rookie QB flags added.\")\n","except Exception as e:\n","    print(f\" -> Skipped Rookie QBs: {e}\")\n","\n","# --- C. Injuries ---\n","try:\n","    # Count players with \"Out\" or \"IR\" status\n","    key_pos = ['QB', 'RB', 'WR', 'TE', 'OL', 'DL', 'LB', 'DB']\n","    inj_counts = injury_df[\n","        (injury_df['report_status'].isin(['Out', 'Injured Reserve'])) &\n","        (injury_df['position'].str.contains('|'.join(key_pos)))\n","    ].groupby(['season', 'week', 'team']).size().reset_index(name='key_injuries')\n","\n","    features_df = features_df.merge(inj_counts, left_on=['season', 'week', 'home_team'], right_on=['season', 'week', 'team'], how='left').rename(columns={'key_injuries': 'home_injuries'}).drop(columns='team')\n","    features_df = features_df.merge(inj_counts, left_on=['season', 'week', 'away_team'], right_on=['season', 'week', 'team'], how='left').rename(columns={'key_injuries': 'away_injuries'}).drop(columns='team')\n","    features_df[['home_injuries', 'away_injuries']] = features_df[['home_injuries', 'away_injuries']].fillna(0)\n","    print(\" -> Injury counts added.\")\n","except Exception as e:\n","    print(f\" -> Skipped Injuries (Data might not be loaded or column names differ): {e}\")"],"metadata":{"id":"fQSTHTrkeKoE","executionInfo":{"status":"ok","timestamp":1764877302289,"user_tz":360,"elapsed":125,"user":{"displayName":"Joseph Havens","userId":"14169325784778486808"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"427389cf-8338-4e3b-a8e2-6e8e04bc3ed7"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["Adding context features...\n"," -> Rest days added.\n"," -> Skipped Rookie QBs: 'draft_year'\n"," -> Injury counts added.\n"]}]},{"cell_type":"code","source":["# 5. Save Master Feature Set\n","print(\"\\nFinalizing dataset...\")\n","\n","# Drop early weeks with NaNs (due to rolling windows)\n","features_df = features_df.dropna(subset=[f'home_off_epa_per_play_roll{ROLL_WINDOW_LIST[-1]}'])\n","\n","# Filter for relevant years (2003 onwards, as 2002 is mostly burnt for lag creation)\n","features_df = features_df[features_df['season'] >= 2003]\n","\n","print(f\"Final shape: {features_df.shape}\")\n","\n","# Save\n","save_path = config.FEATURES_DIR / 'features_master_2003_2023.parquet'\n","features_df.to_parquet(save_path, index=False)\n","print(f\"Saved Master Features to: {save_path}\")"],"metadata":{"id":"ZYW3k1ryeMQT","executionInfo":{"status":"ok","timestamp":1764877302594,"user_tz":360,"elapsed":306,"user":{"displayName":"Joseph Havens","userId":"14169325784778486808"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1ebb386f-e6a5-42fa-dcdc-434e364b9163"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Finalizing dataset...\n","Final shape: (5071, 132)\n","Saved Master Features to: /content/drive/MyDrive/NFL_Prediction_System/data/features/features_master_2003_2023.parquet\n"]}]},{"cell_type":"code","source":["# 11. --- Final Cleanup and Save ---\n","print(\"\\n--- Final Cleanup and Save ---\")\n","\n","# Drop any game from before 2003 (since 2002 has no \"last_season\" data)\n","features_df_final = features_df[features_df['season'] >= 2003].copy()\n","\n","# Drop rows with any remaining NaNs (e.g., from rolling windows in early season)\n","# This is critical for model training\n","features_df_final = features_df_final.dropna(subset=[col for col in features_df_final.columns if '_roll' in col])\n","\n","# Define final columns to keep\n","# We want game info, the target, spread_line, and our engineered features\n","base_cols = ['game_id', 'season', 'week', 'home_team', 'away_team', 'home_score', 'away_score', 'spread_line', 'home_win']\n","\n","# Get all our engineered feature columns\n","# Note: We filter columns dynamically to avoid KeyErrors if a step was skipped\n","potential_features = [\n","    'is_dome', 'temperature', 'wind_speed',\n","    'rookie_qb_matchup', 'home_rookie_qb', 'away_rookie_qb',\n","    'rest_advantage', 'home_rest', 'away_rest',\n","    'home_last_season_win_pct', 'away_last_season_win_pct', 'last_season_win_pct_adv',\n","    'home_key_players_out', 'away_key_players_out', 'injury_advantage'\n","]\n","existing_features = [col for col in potential_features if col in features_df_final.columns]\n","rolling_features = [col for col in features_df_final.columns if '_roll' in col or '_matchup' in col]\n","\n","# Combine all columns\n","final_cols = base_cols + existing_features + list(set(rolling_features) - set(existing_features))\n","\n","# Select only the columns that exist\n","final_df = features_df_final[final_cols].copy()\n","\n","# Save the master feature dataset\n","save_path = config.FEATURES_DIR / 'features_master_2003_2023.parquet'\n","final_df.to_parquet(save_path, index=False)\n","\n","print(f\"Final master feature dataset shape: {final_df.shape}\")\n","print(f\"\\nSuccessfully created and saved master feature dataset to:\")\n","print(save_path)"],"metadata":{"id":"V1isgvYS0WS5","executionInfo":{"status":"ok","timestamp":1764877302647,"user_tz":360,"elapsed":51,"user":{"displayName":"Joseph Havens","userId":"14169325784778486808"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"422e6e61-ecf1-4c39-aa0d-ae788f8f62a3"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Final Cleanup and Save ---\n","Final master feature dataset shape: (4753, 102)\n","\n","Successfully created and saved master feature dataset to:\n","/content/drive/MyDrive/NFL_Prediction_System/data/features/features_master_2003_2023.parquet\n"]}]}]}