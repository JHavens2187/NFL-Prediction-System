{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNFdgWjbcvCGxJ3yx1NfmSR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"IrCKSNDqFif1"},"outputs":[],"source":["import streamlit as st\n","import pandas as pd\n","import numpy as np\n","import nflreadpy as nfl\n","import pickle\n","import os\n","import sys\n","from datetime import datetime\n","\n","# --- CONFIGURATION ---\n","st.set_page_config(page_title=\"NFL War Room\", layout=\"wide\", page_icon=\"üèà\")\n","\n","# Constants\n","CURRENT_SEASON = 2025  # Update this as needed\n","LAG_SEASON = CURRENT_SEASON - 1\n","MODEL_DIR = './models' # Path relative to where you run the script\n","DATA_DIR = './data'\n","\n","# --- 1. DATA LOADING & ENGINEERING (The \"Brain\" Pipeline) ---\n","@st.cache_data(ttl=3600)  # Cache data for 1 hour to prevent constant redownloading\n","def load_and_prep_data(current_season, lag_season):\n","    \"\"\"\n","    Fetches live data from nflreadpy and reconstructs the feature matrix.\n","    This replaces the manual notebook cells.\n","    \"\"\"\n","    with st.spinner(f'Fetching Data for {lag_season}-{current_season}...'):\n","        # 1. Fetch PBP & Schedule\n","        pbp = nfl.load_pbp(seasons=[lag_season, current_season]).to_pandas()\n","        pbp = pbp[pbp['season_type'] == 'REG']\n","\n","        schedule = nfl.load_schedules().to_pandas()\n","        schedule = schedule[\n","            (schedule['season'].isin([lag_season, current_season])) &\n","            (schedule['game_type'] == 'REG')\n","        ]\n","\n","        # 2. Feature Engineering (Condensed Version)\n","        pbp['pass_epa'] = np.where(pbp['play_type'] == 'pass', pbp['epa'], np.nan)\n","        pbp['rush_epa'] = np.where(pbp['play_type'] == 'run', pbp['epa'], np.nan)\n","        pbp['turnover'] = pbp['fumble_lost'] + pbp['interception']\n","\n","        game_stats = pbp.groupby(['season', 'week', 'game_id', 'posteam']).agg({\n","            'epa': 'mean', 'success': 'mean', 'pass_epa': 'mean', 'rush_epa': 'mean', 'turnover': 'sum'\n","        }).reset_index()\n","        game_stats.columns = ['season', 'week', 'game_id', 'team', 'off_epa_per_play', 'off_success_rate', 'off_pass_epa', 'off_run_epa', 'off_turnovers']\n","\n","        def_stats = game_stats.copy().rename(columns={\n","            'team': 'defteam', 'off_epa_per_play': 'def_epa_per_play', 'off_success_rate': 'def_success_rate',\n","            'off_pass_epa': 'def_pass_epa', 'off_run_epa': 'def_run_epa', 'off_turnovers': 'def_turnovers_forced'\n","        })\n","\n","        # Schedule & Rest\n","        schedule['gameday'] = pd.to_datetime(schedule['gameday'])\n","        # Identify Home/Away for the base skeleton\n","        base_games = pd.concat([\n","            schedule[['game_id', 'season', 'week', 'home_team', 'spread_line']].rename(columns={'home_team': 'team'}).assign(is_home=1),\n","            schedule[['game_id', 'season', 'week', 'away_team', 'spread_line']].rename(columns={'away_team': 'team'}).assign(is_home=0)\n","        ])\n","\n","        # Calculate Rest\n","        team_sched = base_games[['season', 'week', 'team']].merge(schedule[['game_id', 'gameday']], on='game_id')\n","        team_sched = team_sched.sort_values(['team', 'season', 'week'])\n","        team_sched['rest_days'] = (team_sched['gameday'] - team_sched.groupby('team')['gameday'].shift(1)).dt.days.fillna(7)\n","\n","        # Merge Stats & Rest back to Base\n","        base_games = base_games.merge(game_stats, on=['game_id', 'team'], how='left')\n","\n","        # Map Opponents for Defense Stats\n","        opp_map = pd.concat([\n","            schedule[['game_id', 'home_team', 'away_team']].rename(columns={'home_team': 'team', 'away_team': 'opponent'}),\n","            schedule[['game_id', 'away_team', 'home_team']].rename(columns={'away_team': 'team', 'home_team': 'opponent'})\n","        ])\n","        base_games = base_games.merge(opp_map, on=['game_id', 'team'], how='left')\n","        base_games = base_games.merge(def_stats, left_on=['game_id', 'opponent'], right_on=['game_id', 'defteam'], how='left')\n","        base_games = base_games.merge(team_sched[['game_id', 'team', 'rest_days']], on=['game_id', 'team'], how='left')\n","\n","        # Rolling Calculations\n","        rolling_metrics = [\n","            'off_epa_per_play', 'off_success_rate', 'off_pass_epa', 'off_run_epa', 'off_turnovers',\n","            'def_epa_per_play', 'def_success_rate', 'def_pass_epa', 'def_run_epa', 'def_turnovers_forced'\n","        ]\n","        windows = [3, 5, 8]\n","        base_games = base_games.sort_values(['team', 'season', 'week'])\n","        grouped = base_games.groupby('team')\n","\n","        for window in windows:\n","            for col in rolling_metrics:\n","                base_games[f'{col}_roll{window}'] = grouped[col].shift(1).rolling(window=window, min_periods=1).mean()\n","\n","        # Final Matchup Matrix (Home vs Away Row)\n","        val_df = base_games[(base_games['season'] == current_season) & (base_games['is_home'] == 1)].copy()\n","        away_df = base_games[(base_games['season'] == current_season) & (base_games['is_home'] == 0)].copy()\n","        final_df = val_df.merge(away_df, on='game_id', suffixes=('', '_away'))\n","\n","        # Differentials\n","        for window in windows:\n","            for col in rolling_metrics:\n","                final_df[f'home_{col}_roll{window}'] = final_df[f'{col}_roll{window}']\n","                final_df[f'away_{col}_roll{window}'] = final_df[f'{col}_roll{window}_away']\n","\n","                if 'off_' in col:\n","                    def_col = col.replace('off_', 'def_')\n","                    if col == 'off_turnovers': def_col = 'def_turnovers_forced'\n","\n","                    if f'{def_col}_roll{window}_away' in final_df.columns:\n","                        final_df[f'home_{col}_matchup_roll{window}'] = final_df[f'{col}_roll{window}'] - final_df[f'{def_col}_roll{window}_away']\n","                        final_df[f'away_{col}_matchup_roll{window}'] = final_df[f'{col}_roll{window}_away'] - final_df[f'{def_col}_roll{window}']\n","\n","        final_df['home_rest'] = final_df['rest_days']\n","        final_df['away_rest'] = final_df['rest_days_away']\n","        final_df['rest_advantage'] = final_df['home_rest'] - final_df['away_rest']\n","\n","        return final_df\n","\n","# --- 2. LOAD MODELS ---\n","@st.cache_resource\n","def load_models(models_dir):\n","    # Adjust paths based on your actual folder structure\n","    # Try looking in common locations\n","    possible_paths = [\n","        models_dir,\n","        \"/content/drive/MyDrive/NFL_Prediction_System/models\", # Colab path\n","        \"models\" # Local path\n","    ]\n","\n","    nv_path = None\n","    scaler_path = None\n","\n","    for path in possible_paths:\n","        if os.path.exists(os.path.join(path, \"ensemble\", \"nv_nuclear_ensemble.pkl\")):\n","            nv_path = os.path.join(path, \"ensemble\", \"nv_nuclear_ensemble.pkl\")\n","            scaler_path = os.path.join(path, \"baseline\", \"NV\", \"nv_scaler.pkl\")\n","            break\n","\n","    if not nv_path:\n","        st.error(\"‚ùå Could not find model files! Please check paths.\")\n","        return None, None\n","\n","    with open(nv_path, 'rb') as f:\n","        model = pickle.load(f)\n","    with open(scaler_path, 'rb') as f:\n","        scaler = pickle.load(f)\n","\n","    return model, scaler\n","\n","# --- 3. UI & LOGIC ---\n","\n","# Sidebar: Controls\n","st.sidebar.header(\"üí∞ Bankroll Manager\")\n","bankroll = st.sidebar.number_input(\"Current Bankroll ($)\", value=1000, step=100)\n","kelly_fraction = st.sidebar.slider(\"Kelly Fraction (Risk Tolerance)\", 0.1, 1.0, 0.25, 0.05)\n","min_edge = st.sidebar.slider(\"Minimum Edge %\", 0.0, 0.20, 0.05, 0.01)\n","\n","# Main Title\n","st.title(\"üèà NFL War Room: Prediction Dashboard\")\n","st.markdown(f\"**Season:** {CURRENT_SEASON} | **Model:** NV Nuclear Ensemble (60% Acc)\")\n","\n","# Load Everything\n","data = load_and_prep_data(CURRENT_SEASON, LAG_SEASON)\n","model, scaler = load_models(MODEL_DIR)\n","\n","if data is not None and model is not None:\n","    # --- Prediction Logic ---\n","\n","    # 1. Feature Alignment\n","    # We need to ensure we only use the columns the model was trained on\n","    try:\n","        # Try to get features from XGBoost estimator\n","        model_features = model.estimators_[0].feature_names_in_\n","    except:\n","        # Fallback: manually define or load a reference\n","        st.warning(\"‚ö†Ô∏è Could not read feature names from model. Using dynamic alignment.\")\n","        # Create a dummy list based on dataframe intersection\n","        model_features = [c for c in data.columns if np.issubdtype(data[c].dtype, np.number)]\n","        # This is risky in production, usually you load a feature_list.pkl\n","\n","    # Create input matrix\n","    X = pd.DataFrame(0, index=data.index, columns=model_features)\n","    for col in model_features:\n","        if col in data.columns:\n","            X[col] = data[col]\n","\n","    # Scale\n","    X_scaled = scaler.transform(X)\n","\n","    # Predict\n","    probs = model.predict_proba(X_scaled)[:, 1]\n","\n","    # Implied Vegas Prob\n","    vegas_probs = 1 / (1 + 10 ** (data['spread_line'] / 14.5))\n","\n","    # Create Display Dataframe\n","    display_df = data[['week', 'team', 'opponent', 'spread_line']].copy()\n","    display_df.columns = ['Week', 'Home', 'Away', 'Spread']\n","    display_df['Model_Win_Prob'] = probs\n","    display_df['Vegas_Win_Prob'] = vegas_probs\n","    display_df['Edge'] = display_df['Model_Win_Prob'] - display_df['Vegas_Win_Prob']\n","\n","    # --- UI: Week Selector ---\n","    available_weeks = sorted(display_df['Week'].unique())\n","    selected_week = st.selectbox(\"Select Week\", available_weeks, index=len(available_weeks)-1)\n","\n","    # Filter by Week\n","    week_data = display_df[display_df['Week'] == selected_week].copy()\n","\n","    # --- CALCULATE BETS ---\n","    bets = []\n","    for idx, row in week_data.iterrows():\n","        edge = row['Edge']\n","\n","        # Filter by Min Edge\n","        if abs(edge) < min_edge:\n","            rec = \"No Bet\"\n","            size = 0.0\n","            pick = \"-\"\n","        else:\n","            # Direction\n","            if edge > 0:\n","                pick = f\"{row['Home']} (Home)\"\n","                my_p = row['Model_Win_Prob']\n","            else:\n","                pick = f\"{row['Away']} (Away)\"\n","                my_p = 1 - row['Model_Win_Prob']\n","\n","            # Kelly Calc\n","            b = 0.909\n","            q = 1 - my_p\n","            kelly = (b * my_p - q) / b\n","\n","            # Constraints\n","            wager_pct = max"]}]}